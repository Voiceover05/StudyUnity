## Planning for user testing

# Define the objectives

- What you want to learn about your project
- What you will show the users to elicit feedback

# Prepare the questions

Open-ended questions give the user freedom to explain their answers. Examples include:
- How well you think the design/prototype/product addresses (a user need)?
- What were the moments in testing where you felt confused, and why?
- How woud you improve this experience?

Closed-ended questions have predetermined answers, like those found in serveys. These might include:
- A series of statements which the user will grade their response to, for example rating confidence on a scale from 1 to 5.
- Questions with simple Yes/No responses

# Plan the testing sessions

- Identify the best time and date.
- Determine how to find testers from your target audience.
- Identify the ideal number of testers.
- Create an agenda for the testing sessions.
- Plan th record the session (if applicable)
- Choose a leader and note-takers for the session, if working in a team.

## Preparing yourself to run the session

# Observe rather than guide

There is a balance to be stuck here - if your testers are struggling with something so basic that they can't test your product, wait at least 30 seconds, make a note of it and then tell them what to do so you can get more information. On the other hand, if they can work through the problem, their solution will be valuable information for improving your design.

# Don't explain or justify your design choises

If you gather qualitative feedback - for example, by having a conversation with the tester - again you may be tempt to explain things or justify the current implementation of your project. This can feel good, but it will not fix what you're testing.

# Don't problem-solve during testing

The user insights that come up during testing may immiately send you into problem-solving mode, thinking about how to correct any issues raised. Your tester may also start to focus on this, exploring potential solutions they think of rather than focusing on their experience.

The purpose of the testing session is to gain insights about their experience and to get deep information about their issues. 

## Facilitating the session

- Make introductions if testing as a group
- Identify the goal of the session
- Explain the recording policy and confirm the tester's consent to this.
- Proide the materials for testing, and observe the testers as they use or review them.
- Ask the questions you have prepared.
- Provide summaries of participant answers for clarification purposes.
- Close the session.

# Tips and tricks for facilitating

- Remind yourself that you are not your product, and every product gets better with feedback - but onl if you're paying attention to what your users are telling you.
- Frame the experience for participants. As each tester comes in, talk with them and explain what a user test is. Emphasize that you want all feedback, and negative feedback can actually be more helpful. Ask them to talk or "narate" as much as possible while using the product or reviewing the materials, so that you can get a deeper understanding of their thought processes.
- When the testing begins, make sure that you stop talking and record your observations in detail. Things that seem clear in the moment can easily get fuzzy if you only rely on you memory. What does the user struggle with? Is there any feature they're not using as intended? Are they doing things that don't seem to make sense?
- If the user stops talking for a while, gently remind them to turn on the interior monologue again, but otherwise pretend you're behind a one-way mirror.
- If you conduct a conversation with a group of testers, make sure to include them all. Gently prompt quiter testers for their thoughts to make sure their insignts are included.

## After the session

Immediately after the testing session, you should
- Make sure the session was recorded (if applicable)
- Write down any additional notes or observations.
- Debrief with fellow team members.
- Create a summary document highligting areas to address.
- Determine what you will and will not change based on the data and feedback collected.

# Evaluating and acting on feedback

Thoroughly read your notes and the questioinaires, and write down a summary of the results, whether positive or negative. This should be a bulleted list of statements, for example:
- User didn't notice that there were different kinds of towers.
- Users found it easy to understand and use the in-context menus.

Once you've done this, consider the action(s) you could take to address each issue where improvement may be necessary, and any dependencies these actions might have. This will help you evaluate the options you have for responding to the issues identified.
